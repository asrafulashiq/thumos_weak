import torch
import torch.nn.functional as F
import utils
import numpy as np
from torch.autograd import Variable
from classificationMAP import getClassificationMAP as cmAP
from detectionMAP import getDetectionMAP as dmAP
import scipy.io as sio
from sklearn.metrics import accuracy_score
from tqdm import tqdm
from eval_detection import ANETdetection
import pandas as pd
import multiprocessing as mp
from joblib import Parallel, delayed



def iou_with_anchors(anchors_min, anchors_max, box_min, box_max):
    """Compute jaccard score between a box and the anchors.
    """
    len_anchors = anchors_max - anchors_min
    int_xmin = np.maximum(anchors_min, box_min)
    int_xmax = np.minimum(anchors_max, box_max)
    inter_len = np.maximum(int_xmax - int_xmin, 0.)
    union_len = len_anchors - inter_len + box_max - box_min
    # print inter_len,union_len
    jaccard = np.divide(inter_len, union_len)
    return jaccard


def soft_nms(df, alpha=0.4, t1=0.5, t2=0.9):
    '''
    df: proposals generated by network;
    alpha: alpha value of Gaussian decaying function;
    t1, t2: threshold for soft nms.
    '''
    df = df.sort_values(by="score", ascending=False)
    tstart = list(df["t-start"].values[:])
    tend = list(df["t-end"].values[:])
    tscore = list(df["score"].values[:])
    tlabels = list(df["label"].values[:])

    rstart = []
    rend = []
    rscore = []
    rlabel = []

    while len(tscore) > 1 and len(rscore) < 101:
        max_index = tscore.index(max(tscore))
        tmp_iou_list = iou_with_anchors(
            np.array(tstart),
            np.array(tend), tstart[max_index], tend[max_index])
        for idx in range(0, len(tscore)):
            if idx != max_index:
                tmp_iou = tmp_iou_list[idx]
                tmp_width = tend[max_index] - tstart[max_index]
                if tmp_iou > t1 + (t2 - t1) * tmp_width:
                    tscore[idx] = tscore[idx] * np.exp(-np.square(tmp_iou) /
                                                       alpha)

        rstart.append(tstart[max_index])
        rend.append(tend[max_index])
        rscore.append(tscore[max_index])
        rlabel.append(tlabels[max_index])
        tstart.pop(max_index)
        tend.pop(max_index)
        tscore.pop(max_index)
        tlabels.pop(max_index)

    newDf = pd.DataFrame()
    newDf['score'] = rscore
    newDf['t-start'] = rstart
    newDf['t-end'] = rend
    newDf['label'] = rlabel
    return newDf


def _post_process(each_grp, df_groups):
    vid_id = each_grp
    cur_group = df_groups.get_group(each_grp)
    newdf = soft_nms(cur_group)
    newdf.insert(0, "video-id", [vid_id]*newdf.shape[0], True)
    duration = cur_group["duration"].values[0]
    newdf["t-start"] = np.maximum(newdf["t-start"].values, 0) * duration
    newdf["t-end"] = np.minimum(newdf["t-end"].values, 1) * duration
    return newdf


def video_post_process(df, video_info):
    # group by video id
    df_groups = df.groupby('video-id')
    list_df = []
    # for each_grp in df_groups.groups.keys():
    #     vid_id = each_grp
    #     cur_group = df_groups.get_group(each_grp)
    #     newdf = soft_nms(cur_group)
    #     newdf.insert(0, "video-id", [vid_id]*newdf.shape[0], True)
    #     duration = cur_group["duration"].values[0]
    #     newdf["t-start"] = np.maximum(newdf["t-start"].values, 0) * duration
    #     newdf["t-end"] = np.minimum(newdf["t-end"].values, 1) * duration
    #     list_df.append(newdf)
    list_df = Parallel(n_jobs=5)(
        delayed(_post_process)(
            each_grp, df_groups
        )
        for each_grp in df_groups.groups.keys()
    )
    mod_df = pd.concat(list_df)
    return mod_df


@torch.no_grad()
def test_bmn(itr, dataset, args, model, logger, device):
    model.eval()

    done = False
    instance_logits_stack = []
    element_logits_stack = []
    len_stack = []
    labels_stack = []
    ind_stack = []

    iou = [0.1, 0.3, 0.5, 0.7]
    dmap_detect = ANETdetection(dataset.path_to_annotations, iou, args=args)

    counter = 0

    segment_predict =  []
    for features, labels, idx in tqdm(dataset.load_test()):
        ind_stack.append(idx)

        features_in, flag = utils.len_extract(features, args.max_seqlen)

        # features_in = features
        features_in = torch.from_numpy(features_in).float().to(device)
        features_in = features_in.unsqueeze(0)

        element_logits, instance_logits, conf_map = model(features_in, is_training=False)
        element_logits = element_logits.squeeze()  # cls, T
        instance_logits = torch.softmax(
            instance_logits.squeeze(), dim=-1
        )  # --> 1, cls
        # conf_map = conf_map.squeeze()  # 3*cls, T, T

        if flag is not None:
            if flag[0] == "pad":
                _seq = flag[1]
                # conf_map = conf_map[..., :_seq, :_seq]
                element_logits = element_logits[..., :_seq]
            seglen = flag[1]
        else:
            seglen = conf_map.shape[-1]

        element_logits_stack.append(element_logits.permute(1, 0).data.cpu().numpy())
        tmp = instance_logits.squeeze().data.cpu().numpy()
        instance_logits_stack.append(tmp)
        labels_stack.append(labels)

        # _mask = torch.tril(torch.ones_like(conf_map), diagonal=0)
        # conf_map[_mask > 0] = -10000

        # tmp = instance_logits.squeeze().data.cpu().numpy()
        # for c in range(args.num_class):
        #     # if instance_logits[c] < 0.1:
        #     #     continue
        #     tmp_conf_s = conf_map[c]  # --> T, T
        #     tmp_conf_m = conf_map[args.num_class+c]  # --> T, T
        #     tmp_conf_e = conf_map[2*args.num_class+c]  # --> T, T

        #     threshold = (element_logits[c].max() - element_logits[c].min())*0.5 + \
        #             element_logits[c].min()
            
        #     tmp_conf_score = (tmp_conf_m-tmp_conf_s) + (tmp_conf_m-tmp_conf_e)

        #     tmp_mask = (tmp_conf_m > threshold) & (tmp_conf_s < threshold) & \
        #         (tmp_conf_e < threshold)

        #     tmp_conf_score = tmp_conf_score * tmp_mask

        #     _len = tmp_conf_s.shape[-1]

        #     for each_ind in tmp_mask.nonzero():
        #         s, e = each_ind.data.cpu().numpy()
        #         scr = float(tmp_conf_score[s, e].data)
        #         segment_predict.append(
        #             [idx, s/_len, e/_len, scr*tmp[c], c, seglen]
        #         )
        # instance_logits_stack.append(tmp)
        # labels_stack.append(labels)

        # ind_stack.append(idx)
        # # pbar.update()

        counter += 1
        if counter > 5:
            break

    instance_logits_stack = np.array(instance_logits_stack)
    labels_stack = np.array(labels_stack)

    # dmap_detect._import_prediction_bmn(segment_predict)
    dmap_detect._import_prediction(element_logits_stack)

    new_pred = video_post_process(dmap_detect.prediction, dmap_detect.video_info)
    dmap_detect.prediction = new_pred

    dmap = dmap_detect.evaluate(ind_to_keep=ind_stack)

    if args.dataset_name == "Thumos14":
        test_set = sio.loadmat("test_set_meta.mat")["test_videos"][0]
        for i in range(np.shape(labels_stack)[0]):
            if test_set[i]["background_video"] == "YES":
                labels_stack[i, :] = np.zeros_like(labels_stack[i, :])

    cmap = cmAP(instance_logits_stack, labels_stack)
    print("Classification map %f" % cmap)

    for k in range(len(iou)):
        print("Detection map @ %f = %f" % (iou[k], dmap[k] * 100))

    logger.add_scalar("Test Classification mAP", cmap, itr)
    for item in list(zip(dmap, iou)):
        logger.add_scalar(
            "Test Detection mAP @ IoU = " + str(item[1]), item[0], itr
        )
